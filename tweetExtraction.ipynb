{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "KysfaVNpPWR9",
        "outputId": "ab691d73-f70c-4a1f-aef7-9d1806e9e355"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import datetime\n",
        "import pandas as pd\n",
        "\n",
        "# Twitter API\n",
        "bearer_token = \"Your Bearer Token\"\n",
        "\n",
        "# Decide the Range of Date\n",
        "end_date = datetime.datetime.now().date()\n",
        "start_date = end_date - datetime.timedelta(days=6)\n",
        "\n",
        "tweet_list = []\n",
        "\n",
        "# Extracting Tweet For last 7 days\n",
        "for i in range(7):\n",
        "    current_date = start_date + datetime.timedelta(days=i)\n",
        "\n",
        "    # to make request for every hour in a day\n",
        "    for hour in range(23):\n",
        "        start_time = datetime.datetime.combine(current_date, datetime.time(hour, 0)).isoformat() + \"+00:00\"\n",
        "        end_time = datetime.datetime.combine(current_date, datetime.time(hour + 1, 0)).isoformat() + \"+00:00\"\n",
        "\n",
        "        # Deciding parameters\n",
        "        url = \"https://api.twitter.com/2/tweets/search/recent\" \n",
        "        headers = {\n",
        "            \"Authorization\": \"Bearer \" + bearer_token,\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "        params = {\n",
        "            \"query\": \"#yourquery -is:retweet lang:en\",\n",
        "            \"max_results\": 100,\n",
        "            \"start_time\": start_time,\n",
        "            \"end_time\": end_time,\n",
        "            \"tweet.fields\": \"created_at,author_id,public_metrics,entities\"\n",
        "        }\n",
        "\n",
        "        # API request\n",
        "        response = requests.get(url, headers=headers, params=params)\n",
        "        data = response.json()\n",
        "\n",
        "        \n",
        "        for tweet in data.get(\"data\", []):\n",
        "            tweet_id = tweet[\"id\"]\n",
        "            created_at = tweet[\"created_at\"]\n",
        "            author_id = tweet[\"author_id\"]\n",
        "            retweet_count = tweet[\"public_metrics\"][\"retweet_count\"]\n",
        "            like_count = tweet[\"public_metrics\"][\"like_count\"]\n",
        "            text = tweet[\"text\"]\n",
        "\n",
        "            \n",
        "            hashtags = []\n",
        "            if \"entities\" in tweet and \"hashtags\" in tweet[\"entities\"]:\n",
        "                for hashtag in tweet[\"entities\"][\"hashtags\"]:\n",
        "                    hashtags.append(hashtag[\"tag\"])\n",
        "\n",
        "            tweet_dict = {\n",
        "                \"Tweet ID\": tweet_id,\n",
        "                \"Created At\": created_at,\n",
        "                \"Author ID\": author_id,\n",
        "                \"Retweet Count\": retweet_count,\n",
        "                \"Like Count\": like_count,\n",
        "                \"Text\": text,\n",
        "                \"Hashtags\": hashtags\n",
        "            }\n",
        "            tweet_list.append(tweet_dict)\n",
        "\n",
        "        # Controlling rate limits\n",
        "        rate_limit_remaining = int(response.headers.get(\"x-rate-limit-remaining\"))\n",
        "        if rate_limit_remaining == 0:\n",
        "            rate_limit_reset = int(response.headers.get(\"x-rate-limit-reset\"))\n",
        "            current_time = int(datetime.datetime.now().timestamp())\n",
        "            sleep_time = rate_limit_reset - current_time\n",
        "            if sleep_time > 0:\n",
        "                print(f\"Rate limit reached. Waiting for {sleep_time} seconds...\")\n",
        "                time.sleep(sleep_time)\n",
        "\n",
        "df = pd.DataFrame(tweet_list)\n",
        "df.to_csv('tweetslist.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
